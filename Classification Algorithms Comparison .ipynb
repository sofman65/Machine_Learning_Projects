{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a8800b5",
   "metadata": {},
   "source": [
    "# Author : Sofianos Lampropoulos\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "c3f1b6e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.preprocessing import LabelEncoder,OneHotEncoder\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "58523ea7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##DATA READING\n",
    "\n",
    "dataset = pd.read_csv('C:/Users/sofma/Desktop/ECE/PSE/Homeworks/Homework_3_-_Classification/Homework 3 - Classification/E-Commerce.csv')\n",
    "dataset.columns\n",
    "x = dataset[['item.category', 'subcategory', 'brand', 'price']]\n",
    "y = dataset['price']\n",
    "\n",
    "##Data Transformation\n",
    "# one hot encode input variables\n",
    "onehot_encoder = OneHotEncoder(sparse=False)\n",
    "X = onehot_encoder.fit_transform(x)\n",
    "# ordinal encode target variable\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(y)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcb2eb51",
   "metadata": {},
   "source": [
    "### Decision trees:\n",
    "Train 5 different decision trees using the following maximum depths {3, 6, 9, 12, 14}. Using 5-fold cross-validation, estimate the out of sample error for each model, and report them using a table and a labeled bar graph. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "44c9249a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['explained_variance', 'r2', 'max_error', 'neg_median_absolute_error', 'neg_mean_absolute_error', 'neg_mean_absolute_percentage_error', 'neg_mean_squared_error', 'neg_mean_squared_log_error', 'neg_root_mean_squared_error', 'neg_mean_poisson_deviance', 'neg_mean_gamma_deviance', 'accuracy', 'top_k_accuracy', 'roc_auc', 'roc_auc_ovr', 'roc_auc_ovo', 'roc_auc_ovr_weighted', 'roc_auc_ovo_weighted', 'balanced_accuracy', 'average_precision', 'neg_log_loss', 'neg_brier_score', 'adjusted_rand_score', 'rand_score', 'homogeneity_score', 'completeness_score', 'v_measure_score', 'mutual_info_score', 'adjusted_mutual_info_score', 'normalized_mutual_info_score', 'fowlkes_mallows_score', 'precision', 'precision_macro', 'precision_micro', 'precision_samples', 'precision_weighted', 'recall', 'recall_macro', 'recall_micro', 'recall_samples', 'recall_weighted', 'f1', 'f1_macro', 'f1_micro', 'f1_samples', 'f1_weighted', 'jaccard', 'jaccard_macro', 'jaccard_micro', 'jaccard_samples', 'jaccard_weighted'])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn.metrics.SCORERS.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "8d3127eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sofma\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=3.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "C:\\Users\\sofma\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=3.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "C:\\Users\\sofma\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=3.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "C:\\Users\\sofma\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=3.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "C:\\Users\\sofma\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=3.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_scores_list = []\n",
    "cv_scores_mean = []\n",
    "accuracy_scores = []\n",
    "tree_depths = [3,6,9,12,14]\n",
    "for depth in tree_depths:\n",
    "    tree_model = DecisionTreeClassifier(max_depth=depth)\n",
    "    cv_scores = cross_val_score(tree_model, X, y, cv=3, scoring='accuracy')\n",
    "    cv_scores_list.append(cv_scores)\n",
    "    cv_scores_mean.append(cv_scores.mean())\n",
    "    accuracy_scores.append(tree_model.fit(X, y).score(X, y))\n",
    "cv_scores_mean = np.array(cv_scores_mean)\n",
    "accuracy_scores = np.array(accuracy_scores)\n",
    "\n",
    "\n",
    "\n",
    "tree_model.score(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "924bc078",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single tree depth:  14\n",
      "Accuracy, Training Set:  100.0 %\n",
      "Accuracy, Test Set:  37.5 %\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,random_state = 0)\n",
    "\n",
    "def run_single_tree(X_train, y_train, X_test, y_test, depth = 14):\n",
    "    \n",
    "    model = DecisionTreeClassifier(max_depth=depth).fit(X_train, y_train)\n",
    "    accuracy_train = model.score(X_train, y_train)\n",
    "    accuracy_test = model.score(X_test, y_test)\n",
    "    print('Single tree depth: ', depth)\n",
    "    print('Accuracy, Training Set: ', round(accuracy_train*100,5), '%')\n",
    "    print('Accuracy, Test Set: ', round(accuracy_test*100,5), '%')\n",
    "    return accuracy_train, accuracy_test\n",
    "  \n",
    "\n",
    "# train and evaluate a 5-depth tree\n",
    "sm_best_tree_accuracy_train, sm_best_tree_accuracy_test = run_single_tree(X_train, y_train, \n",
    "                                                                          X_test, y_test, \n",
    "                                                                         14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "9fb57239",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3666666666666667\n",
      "{'max_depth': 14, 'min_samples_leaf': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sofma\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=3.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "num_leafs = [1, 5, 10, 20, 50, 100]\n",
    "param_grid = [{'max_depth':[3,6,9,12,14],\n",
    "              'min_samples_leaf':num_leafs}]\n",
    "dt = GridSearchCV(estimator=DecisionTreeClassifier(), param_grid=param_grid, scoring='accuracy', cv=3)\n",
    "dt = gs.fit(X, y)\n",
    "print(dt.best_score_)\n",
    "print(dt.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "6e6ba416",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['ccp_alpha', 'class_weight', 'criterion', 'max_depth', 'max_features', 'max_leaf_nodes', 'min_impurity_decrease', 'min_impurity_split', 'min_samples_leaf', 'min_samples_split', 'min_weight_fraction_leaf', 'random_state', 'splitter'])"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DecisionTreeClassifier().get_params().keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "936ef6aa",
   "metadata": {},
   "source": [
    "## Nearest neighbors:\n",
    "\n",
    "Train 5 different nearest neighbors classifiers using the following number of neighbors {3, 5, 7, 9, 11}.\n",
    "Using 5-fold cross-validation, i estimate the out of sample error for each model, and report them using a table and a labeled bar graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "a6d2a337",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 40 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sofma\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=3.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'algorithm': 'auto', 'n_neighbors': 5, 'weights': 'distance'}\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "kn = KNeighborsClassifier()\n",
    "params = {\n",
    "    'n_neighbors' : [3, 5, 7, 9, 11],\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute']\n",
    "}\n",
    "grid_kn = GridSearchCV(estimator = kn,\n",
    "                        param_grid = params,\n",
    "                        scoring = 'accuracy', \n",
    "                        cv = 3, \n",
    "                        verbose = 1,\n",
    "                        n_jobs = -1)\n",
    "grid_kn.fit(X, y)\n",
    "\n",
    "# extract best estimator\n",
    "print(grid_kn.best_params_)\n",
    "# to test the bestfit\n",
    "print(grid_kn.score(X, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "967a0d59",
   "metadata": {},
   "source": [
    "##  Neural networks:\n",
    "Train 3 neural networks using {5, 40, 70} hidden-layer neurons. Using 5-fold cross-validation, estimate the out of sample error for each model, and report them using a table and a labeled bar graph.  Choose the model with lowest estimated out of sample error, and record its max depth in the dictionary in the best_hyperparams() function.  Make sure that your report clearly states which model was chosen and what was the predicted out of sample error for it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "fbade58a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 2970 candidates, totalling 8910 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sofma\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:666: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=3.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "{'alpha': 0.001, 'hidden_layer_sizes': 40, 'max_iter': 1000, 'random_state': 8, 'solver': 'lbfgs'}\n"
     ]
    }
   ],
   "source": [
    "parameters = {'solver': ['lbfgs'], 'max_iter': [1000,1100,1200,1300,1400,1500,1600,1700,1800,1900,2000 ], 'alpha': 10.0 ** -np.arange(1, 10), 'hidden_layer_sizes':[5,40,70], 'random_state':[0,1,2,3,4,5,6,7,8,9]}\n",
    "clf3 = GridSearchCV(MLPClassifier(), parameters,scoring = 'accuracy', cv = 3, \n",
    "                        verbose = 1, n_jobs=-1)\n",
    "\n",
    "clf3.fit(X, y)\n",
    "print(clf3.score(X, y))\n",
    "print(clf3.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72730126",
   "metadata": {},
   "source": [
    "## Compare  the classification algorithms:\n",
    "Between decision trees, nearest neighbors, and neural networks, which classification  algorithm worked the best for you? Were there trade-offs between them?\n",
    "For a much larger training set and an optimal choice of hyperparameters, which algorithm do you expect to preform best in terms of accuracy? In terms of efficiency?  Explain why using your theoretical knowledge of the algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "3d294f99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing Results\n",
      "ANN  is more accurate than KNN Classification and Decision Tree\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "def printComparisonResults(KnnAccuracy,dectreeAccuracy,ANNAccuracy):\n",
    "    print(\"Printing Results\")\n",
    "\n",
    "    lr = \"KNN Classification\"\n",
    "    dt = \"Decision Tree\"\n",
    "    sv = \"ANN \"\n",
    "\n",
    "    if KnnAccuracy > (dectreeAccuracy and ANNAccuracy):\n",
    "        print(lr, \"is more accurate than\", dt, \"and\", sv)\n",
    "    elif dectreeAccuracy > (KnnAccuracy and ANNAccuracy):\n",
    "        print(dt, \"is more accurate than\", lr, \"and\", sv)\n",
    "    else:\n",
    "        print(sv, \"is more accurate than\", lr, \"and\", dt)\n",
    "\n",
    "    print(\"Done\")\n",
    "\n",
    "printComparisonResults(grid_kn.score(X, y),dt.best_score_,clf3.score(X, y))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77c343e0",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e920b35a",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa16d53d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
