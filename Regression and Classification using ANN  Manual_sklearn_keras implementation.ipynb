{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Epu6oCx0ac14"
   },
   "source": [
    "\n",
    "# Neural Networks\n",
    "\n",
    "\n",
    "This project explores the application of artificial neural networks (ANN) in both classification and regression tasks. We use three different methods for ANN implementation: a) NumPy, b) Scikit-learn, and c) Keras (with TensorFlow backend). Additionally, we compare the performance of ANN with Decision Tree models for both tasks.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f7oB5HYIac17"
   },
   "source": [
    "# Structure of Neural Networks\n",
    "\n",
    "\\begin{definition}\n",
    "Within an artificial neural network (ANN), a neuron is a mathematical function that model the functioning of a biological neuron. Typically, a neuron compute the weighted average of its input, and this sum is passed through a nonlinear function, often called activation function, such as the sigmoid.\n",
    "\n",
    "![](ANN.png)\n",
    "\n",
    "![](content_content_neuron.png)\n",
    "\n",
    "\\end{definition}\n",
    "\n",
    "\n",
    "__transfer function between neurons__\n",
    "\n",
    "- The sigmoid equation is what is typically used as a transfer function between neurons. It is similar to the step fuction, but is continuous and differentiable.\n",
    "\n",
    "$$ \\sigma(x) = \\frac{1}{1+e^{-x}}$$\n",
    "\n",
    "- One useful property of this transfer function is the simplicity of computing its derivative.\n",
    "\n",
    "$$\\frac{d}{dx}\\sigma(x) = \\sigma' = \\sigma(x) (1-\\sigma(x))$$\n",
    "\n",
    "__Single input neuron__\n",
    "\n",
    "<img src=\"./image_files/single_neuron.png\" width = 300>\n",
    "\n",
    "$$ O = \\sigma(\\xi \\omega + \\theta) $$\n",
    "\n",
    "__Multiple input neuron__\n",
    "\n",
    "<img src=\"./image_files/multiple_neuron.png\" width = 300>\n",
    "\n",
    "$$ O = \\sigma(\\xi_1 \\omega_1 + \\xi_2 \\omega_2 + \\xi_3 \\omega_3 +\\theta) $$\n",
    "\n",
    "__A neural network__\n",
    "\n",
    "<img src=\"./image_files/nn_03.png\" width = 300>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s_brVY6Wac18"
   },
   "source": [
    "# Schematic Description of Neural Network Algorithm \n",
    "![](https://cdn.mathpix.com/snip/images/BNm1t92nEvmj7bnmNZZMEpOgR8bNVfI-JELGa3uTJDw.original.fullsize.png)\n",
    "\n",
    "Figure 1 - The loss score is used as a feedback signal to adjust the weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Odq0zDtFac19"
   },
   "source": [
    "# Learning: Backpropagation Algorithm\n",
    "\n",
    "__Notation__\n",
    "\n",
    "- $x_j^\\ell$: Input to node $j$ of layer $\\ell$\n",
    "\n",
    "- $W_{ij}^\\ell$: Weight from layer $\\ell - 1$ node $i$ to layer $\\ell$ node $j$\n",
    "\n",
    "- $\\sigma(x) = \\frac{1}{1+e^{-x}}$: Sigmoid transfer function\n",
    "\n",
    "- $\\theta_j^{\\ell}$: Bias of node $j$ of layer $\\ell$\n",
    "\n",
    "- $O_j^{\\ell}$: Output of node $j$ in layer $\\ell$\n",
    "\n",
    "- $t_j$: Target value of node $j$ of the output layer\n",
    "\n",
    "<br>\n",
    "<font size='4'><b>The error calculation</b></font>\n",
    "\n",
    "Given a set of training data points $t_k$ and output layer output $O_k$ we can write the error as\n",
    "\n",
    "$$ E = \\frac{1}{2} \\sum_{k \\in K} (O_k - t_k)^2$$\n",
    "\n",
    "We want to calculate $\\frac{\\partial E}{\\partial W_{jk}^{\\ell}}$, the rate of change of the error with respect to the given connective weight, so we can minimize it.\n",
    "\n",
    "Now we consider two cases: the node is an output node, or it is in a hidden layer\n",
    "\n",
    "__1) Output layer node__\n",
    "\n",
    "\\begin{align*}\n",
    "\\frac{\\partial E}{\\partial W_{jk}} &= \\frac{\\partial}{\\partial W_{jk}} \\frac{1}{2} (O_k - t_k)^2 = (O_k - t_k)\\frac{\\partial}{\\partial W_{jk}} O_k = (O_k - t_k)\\frac{\\partial}{\\partial W_{jk}} \\sigma(x_k)\\\\\n",
    "&= (O_k - t_k) \\sigma(x_k) (1-\\sigma(x_k)) \\frac{\\partial}{\\partial W_{jk}} x_k \\\\\n",
    "&= (O_k - t_k) O_k (1 - O_k) O_j\n",
    "\\end{align*}\n",
    "\n",
    "$\\quad$For notation purposes, I will define $\\delta_k$ to be the expression $(O_k - t_k) O_k (1 - O_k)$, so we can rewrite the equation above as\n",
    "\n",
    "$$\\frac{\\partial E}{\\partial W_{jk}} = O_j \\delta_k $$\n",
    "\n",
    "__2) Hidden layer node__\n",
    "\n",
    "\\begin{align*}\n",
    "\\frac{\\partial E}{\\partial W_{ij}} &= \\frac{\\partial}{\\partial W_{ij}} \\frac{1}{2} \\sum_{k \\in K} (O_k - t_k)^2 = \\sum_{k \\in K} (O_k - t_k)\\frac{\\partial}{\\partial W_{ij}} O_k = \\sum_{k \\in K} (O_k - t_k)\\frac{\\partial}{\\partial W_{ij}} \\sigma(x_k)\\\\\n",
    "&= \\sum_{k \\in K} (O_k - t_k) \\sigma(x_k) (1-\\sigma(x_k)) \\frac{\\partial}{\\partial W_{ij}} x_k \\\\\n",
    "&= \\sum_{k \\in K} (O_k - t_k) O_k (1 - O_k) \\frac{\\partial x_k}{\\partial O_j}\\cdot \\frac{\\partial O_j}{\\partial W_{ij}} = \\sum_{k \\in K} (O_k - t_k) O_k (1 - O_k) W_{jk}\\cdot \\frac{\\partial O_j}{\\partial W_{ij}}\\\\\n",
    "&= \\frac{\\partial O_j}{\\partial W_{ij}} \\cdot \\sum_{k \\in K} (O_k - t_k) O_k (1 - O_k) W_{jk}\\\\\n",
    "&= O_j (1-O_j)\\frac{\\partial x_j}{\\partial W_{ij}} \\cdot \\sum_{k \\in K} (O_k - t_k) O_k (1 - O_k) W_{jk}\\\\\n",
    "&= O_j (1-O_j)O_i \\cdot \\sum_{k \\in K} (O_k - t_k) O_k (1 - O_k) W_{jk}\\\\\n",
    "&= O_i O_j (1-O_j) \\sum_{k \\in K} \\delta_k W_{jk}\n",
    "\\end{align*}\n",
    "\n",
    "$\\quad$Similar to before we will now define all terms besides $O_i$ to be $\\delta_j = O_j (1-O_j) \\sum_{k \\in K} \\delta_k W_{jk}$, so we have\n",
    "\n",
    "$$\\frac{\\partial E}{\\partial W_{ij}} = O_i \\delta_j$$\n",
    "\n",
    "\n",
    "__How weights affect errors__\n",
    "\n",
    "- For an output layer node $k \\in K$\n",
    "\n",
    "$$\\frac{\\partial E}{\\partial W_{jk}} = O_j \\delta_k $$\n",
    "\n",
    "$\\quad \\;\\,$where $$\\delta_k = (O_k - t_k) O_k (1 - O_k)$$\n",
    "\n",
    "- For a hidden layer node $j \\in J$\n",
    "\n",
    "$$\\frac{\\partial E}{\\partial W_{ij}} = O_i \\delta_j$$\n",
    "\n",
    "$\\quad \\;\\,$where $$\\delta_j = O_j (1-O_j) \\sum_{k \\in K} \\delta_k W_{jk}$$\n",
    "\n",
    "__What about the bias?__\n",
    "\n",
    "If we incorporate the bias term $\\theta$ into the equation you will find that\n",
    "\n",
    "$$ \\frac{\\partial O}{\\partial \\theta} = 1$$\n",
    "\n",
    "This is why we view the bias term as output from a node which is always one. This holds for any layer $\\ell$, a substitution into the previous equations gives us that\n",
    "\n",
    "$$ \\frac{\\partial E}{\\partial \\theta} = \\delta_{\\ell}$$\n",
    "\n",
    "<br>\n",
    "<font size='4'><b>The backpropagation algorithm using gradient descent</b></font>\n",
    "\n",
    "1. Run the network forward with your input data to get the netwrok output\n",
    "\n",
    "2. For each output node compute\n",
    "$$\\delta_k = (O_k - t_k) O_k (1 - O_k)$$\n",
    "3. For eatch hidden node calculate\n",
    "$$\\delta_j = O_j (1-O_j) \\sum_{k \\in K} \\delta_k W_{jk}$$\n",
    "4. Update the weights and biases as follows<br>\n",
    "Given\n",
    "\\begin{align*}\n",
    "\\Delta W &= -\\eta \\delta_{\\ell} O_{\\ell -1}\\\\\n",
    "\\Delta \\theta &= -\\eta \\delta_{\\ell}\n",
    "\\end{align*}\n",
    "apply\n",
    "\\begin{align*}\n",
    "W &\\leftarrow W + \\Delta W \\\\\n",
    "\\theta &\\leftarrow \\theta + \\Delta \\theta\n",
    "\\end{align*}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "ndfFcXm1ac2A",
    "outputId": "d5ab7444-16cf-4b86-c874-cffe83e392ef"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe src=\"https://www.youtube.com/embed/aVId8KMsdUU?list=PL29C61214F2146796\" \n",
       "width=\"560\" height=\"315\" frameborder=\"0\" allowfullscreen></iframe>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<iframe src=\"https://www.youtube.com/embed/aVId8KMsdUU?list=PL29C61214F2146796\" \n",
    "width=\"560\" height=\"315\" frameborder=\"0\" allowfullscreen></iframe>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "MbPjsZExac2C",
    "outputId": "8109693c-6ff6-45d0-ebcb-07e457785d40"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe src=\"https://www.youtube.com/embed/zpykfC4VnpM?list=PL29C61214F2146796\" \n",
       "width=\"560\" height=\"315\" frameborder=\"0\" allowfullscreen></iframe>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<iframe src=\"https://www.youtube.com/embed/zpykfC4VnpM?list=PL29C61214F2146796\" \n",
    "width=\"560\" height=\"315\" frameborder=\"0\" allowfullscreen></iframe>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R_Rk9etHac2C"
   },
   "source": [
    "# Implementation in python\n",
    "\n",
    "Try to be very explicit about what parts are \"up in the air\" (i.e. modifiable) so you get a sense of where you can experiment with new neural networks.\n",
    "\n",
    "- [ml4a chapter on neural networks](http://ml4a.github.io/ml4a/neural_networks/). \n",
    "\n",
    "- Michael Nielsen's [Neural Networks and Deep Learning](http://neuralnetworksanddeeplearning.com/), \n",
    "\n",
    "- Goodfellow, Bengio, and Courville's [Deep Learning](http://www.deeplearningbook.org/) book\n",
    "\n",
    "- Yoav Goldberg's \"[A Primer on Neural Network Models for Natural Language Processing](http://arxiv.org/abs/1510.00726)\". \n",
    "\n",
    "\n",
    "For the other neural network guides we will mostly rely on the excellent [Keras](http://keras.io/) library, which makes it very easy to build neural networks and can take advantage of [Theano](http://deeplearning.net/software/theano/) or [TensorFlow](https://www.tensorflow.org/)'s optimizations and speed. However, to demonstrate the basics of neural networks, we'll use `numpy` so we can see exactly what's happening every step of the way.\n",
    "\n",
    "Each unit (neuron) has a vector of weights - these are the parameters that the network learns.\n",
    "\n",
    "The inner operations of the basic unit is straightforward. We collapse the weight vector $w$ and input vector $v$ into a scalar by taking their dot product. Often a _bias_ term $b$ is added to this dot product; this bias is also learned. then we pass this dot product through an _activation function_ $f$, which also returns a scalar. Activation functions are typically nonlinear so that neural networks can learn nonlinear functions. I'll mention a few common activation functions in a bit, but for now let's see what a basic unit is doing:\n",
    "\n",
    "```python\n",
    "def unit(inputs, weights, b):\n",
    "    return activation_function(np.dot(inputs, weights) + b)\n",
    "```\n",
    "\n",
    "Note that the output units often do not have an activation function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zGGYgD3wac2D"
   },
   "source": [
    "## A basic neural network with `numpy`\n",
    "\n",
    "First we'll import `numpy`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PW761L9Tac2E"
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VAa6Al1Xac2E"
   },
   "source": [
    "With machine learning we are trying to find a hidden function that describes data that we have. Here we are going to cheat a little and define the function ourselves and then use that to generate data. Then we'll try to \"reverse engineer\" our data and see if we can recover our original function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yBTguvzOac2F",
    "outputId": "635b79d9-68a0-47e9-d912-741341d1843f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 4.]\n",
      " [29.]\n",
      " [ 9.]]\n"
     ]
    }
   ],
   "source": [
    "def unknown_function(X):\n",
    "    coeff = np.array([[2., -1., 5.]])\n",
    "    return np.dot(X, coeff.T)\n",
    "\n",
    "X = np.array([\n",
    "    [4.,9.,1.],\n",
    "    [2.,5.,6.],\n",
    "    [1.,8.,3.]\n",
    "])\n",
    "\n",
    "t = unknown_function(X) # target\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d77kAqXhac2F"
   },
   "source": [
    "Now we are going to set up our simple neural network. It will have just one hidden layer with two units (which we will refer to as unit 1 and unit 2).\n",
    "\n",
    "<img src=\"./image_files/simple_nn_structure.png\" width = 250>\n",
    "\n",
    "First we have to define the weights (i.e. parameters) of our network.\n",
    "\n",
    "- **We have three inputs each going into two units, then one bias value for each unit, so we have eight parameters for the hidden layer.**\n",
    "\n",
    "- **Then we have the output of those two hidden layer units going to the output layer, which has only one unit - this gives us two more parameters, plus one bias value.**\n",
    "\n",
    "- **So in total, we have eleven parameters.**\n",
    "\n",
    "Let's set them to arbitrary values for now (random initialization)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jKsrZ3j_ac2F"
   },
   "outputs": [],
   "source": [
    "# initial hidden layer weights\n",
    "hidden_layer_weights = np.array([\n",
    "    [0.5, 0.5, 0.5],    # unit 1\n",
    "    [0.1, 0.1, 0.1]     # unit 2\n",
    "])\n",
    "hidden_layer_biases = np.array([1. ,1.])\n",
    "\n",
    "# initial output layer weights\n",
    "output_weights = np.array([[1., 1.]])\n",
    "output_biases = np.array([1.])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v1MjdvC1ac2G"
   },
   "source": [
    "## Activation Functions\n",
    "![](activation_functions.png)\n",
    "\n",
    "\n",
    "We'll use $\\tanh$ activations for our hidden units, so let's define that real quick:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mDzyq2Rnac2G"
   },
   "outputs": [],
   "source": [
    "def activation(X):\n",
    "    return np.tanh(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZFMzQuOpac2G"
   },
   "source": [
    "- $\\tanh$ activations are quite common, but you may also encounter sigmoid activations and, more recently, \n",
    "\n",
    "- ReLU activations (which output 0 when $x \\leq 0$ and output $x$ otherwise). These activation functions have different benefits: \n",
    "\n",
    "- ReLUs in particular are robust against training difficulties that come when dealing with deeper networks.\n",
    "\n",
    "To make things clearer later on, we'll also define the linear function that combines a unit's input with its weights:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hYP59EKMac2H"
   },
   "outputs": [],
   "source": [
    "# linear regression function\n",
    "\n",
    "def linear(input, weights, biases):\n",
    "    return np.dot(input, weights.T) + biases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5pFvPE5Uac2H"
   },
   "source": [
    "Now we can do a forward pass with our inputs $X$ to see what the predicted outputs are.\n",
    "\n",
    "## Forward pass\n",
    "\n",
    "**First, we'll pass the input through the hidden layer:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cxAj53Vwac2H",
    "outputId": "414b10ad-59eb-4f0a-baac-5675f85b22ba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hidden output\n",
      "[[0.99999977 0.98367486]\n",
      " [0.99999939 0.9800964 ]\n",
      " [0.99999834 0.97574313]]\n"
     ]
    }
   ],
   "source": [
    "hidden_linout = linear(X, hidden_layer_weights, hidden_layer_biases)\n",
    "hidden_output = activation(hidden_linout)\n",
    "\n",
    "print('hidden output')\n",
    "print(hidden_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-UD1Qaeiac2H"
   },
   "source": [
    "(We're keeping the neuron unit's intermediary value, `hidden_linout` for use in backpropagation.)\n",
    "\n",
    "**Then we'll take the hidden layer's output and pass it through the output layer to get our predicted outputs:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gN5OLZKsac2I",
    "outputId": "93671e2e-c141-46a3-b5e3-a64f87f04287"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted\n",
      "[[2.98367463]\n",
      " [2.98009578]\n",
      " [2.97574147]]\n"
     ]
    }
   ],
   "source": [
    "hidden_linout = linear(X, hidden_layer_weights, hidden_layer_biases)\n",
    "hidden_output = activation(hidden_linout)\n",
    "\n",
    "\n",
    "output_linout = linear(hidden_output, output_weights, output_biases)\n",
    "output_output = output_linout # no activation function on output layer\n",
    "\n",
    "predicted = output_output\n",
    "print('predicted')\n",
    "print(predicted)\n",
    "\n",
    "mse = np.mean((t - predicted)**2)\n",
    "print('mean squared error')\n",
    "print(mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1n8XCS3uac2I"
   },
   "source": [
    "Now let's compute the mean squared error of our predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GjdTMW7Iac2I",
    "outputId": "0213e10c-0e2b-4203-f50a-301b0681ac8f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean squared error\n",
      "238.12000783695962\n"
     ]
    }
   ],
   "source": [
    "mse = np.mean((t - predicted)**2)\n",
    "print('mean squared error')\n",
    "print(mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uyBJtlbkac2J"
   },
   "source": [
    "Now we can take this error and backpropagate it through the network. This will tell us how to update our weights.\n",
    "\n",
    "## Backpropagation\n",
    "\n",
    "Since backpropagation is essentially a chain of derivatives (that is used for gradient descent), we'll need the derivative of our activation function, so let's define that first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iOiJmpL-ac2J"
   },
   "outputs": [],
   "source": [
    "def activation_deriv(X):\n",
    "    return 1 - np.tanh(X)**2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4-iM7xt6ac2J"
   },
   "source": [
    "Then we want to set a learning rate - this is a value from 0 to 1 which affects how large we tweak our parameters by for each training iteration.\n",
    "\n",
    "- You don't want to set this to be too large or else training will never converge (your parameters might get really big and you'll start seeing a lot of `nan` values).\n",
    "\n",
    "- You don't want to set this to be too small either, otherwise training will be very slow. There are more sophisticated forms of gradient descent that deal with this, but those are beyond the scope of this guide."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BVaUYzshac2J"
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uH56QyL9ac2J"
   },
   "source": [
    "First we'll propagate the error through the output layer (I won't go through the derivation of each step but they are straightforward to work out if you know a bit about derivatives):\n",
    "\n",
    "![](bp.svg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "02G5oCvXac2J"
   },
   "outputs": [],
   "source": [
    "# derivative of mean squared error\n",
    "error = predicted - t\n",
    "\n",
    "# delta for the output layer (no activation on output layer)\n",
    "delta_output = error\n",
    "\n",
    "# output layer updates\n",
    "output_weights_update = delta_output.T.dot(hidden_output)\n",
    "output_biases_update = delta_output.sum(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b05uTgb_ac2K"
   },
   "source": [
    "Then through the hidden layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5VL1s3A9ac2K"
   },
   "outputs": [],
   "source": [
    "# push back the delta to the hidden layer\n",
    "delta_hidden = delta_output*output_weights*activation_deriv(hidden_linout)\n",
    "\n",
    "# hidden layer updates\n",
    "hidden_weights_update = delta_hidden.T.dot(X)\n",
    "hidden_biases_update = delta_hidden.sum(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hiOUYHAFac2K"
   },
   "source": [
    "Then we can apply the updates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I9D6JQ8wac2K"
   },
   "outputs": [],
   "source": [
    "output_weights -= output_weights_update*learning_rate\n",
    "output_biases -= output_biases_update*learning_rate\n",
    "\n",
    "hidden_layer_weights -= hidden_weights_update*learning_rate\n",
    "hidden_layer_biases -= hidden_biases_update*learning_rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rTk9F4Viac2K"
   },
   "source": [
    "That's one training iteration! In reality, you would do this many, many times - feedforward, backpropagate, update weights, then rinse and repeat. That's the basics of a neural network - at least, the \"vanilla\" kind. There are other more sophisticated kinds (recurrent and convolutional neural networks are two of the most common) that are covered in other guides."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PDOegvhqac2K",
    "outputId": "0f2bdaa3-d6ce-423f-f71c-135c1ad3c364"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.98367463]\n",
      " [2.98009578]\n",
      " [2.97574147]]\n"
     ]
    }
   ],
   "source": [
    "print (predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qjd8mL1Jac2K"
   },
   "source": [
    "## 3.4. Neural Networks in python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C3BAqHjBac2L",
    "outputId": "9377974e-ffba-498e-e943-2292a90d178c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 4.]\n",
      " [29.]\n",
      " [ 9.]]\n",
      "[[ 4.96752766]\n",
      " [28.97734771]\n",
      " [ 8.55822613]]\n"
     ]
    }
   ],
   "source": [
    "# hidden layer weights\n",
    "hidden_layer_weights = np.array([\n",
    "    [0.5, 0.5, 0.5],    # unit 1\n",
    "    [0.1, 0.1, 0.1]     # unit 2\n",
    "])\n",
    "hidden_layer_biases = np.array([1. ,1.])\n",
    "\n",
    "# output layer weights\n",
    "output_weights = np.array([[1., 1.]])\n",
    "output_biases = np.array([1.])\n",
    "\n",
    "for i in range(10000):\n",
    "    \n",
    "    hidden_linout = linear(X, hidden_layer_weights, hidden_layer_biases)\n",
    "    hidden_output = activation(hidden_linout)\n",
    "    \n",
    "    output_linout = linear(hidden_output, output_weights, output_biases)\n",
    "    output_output = output_linout # no activation function on output layer\n",
    "\n",
    "    predicted = output_output\n",
    "\n",
    "    # derivative of mean squared error\n",
    "    error = predicted - t\n",
    "\n",
    "    # delta for the output layer (no activation on output layer)\n",
    "    delta_output = error\n",
    "\n",
    "    # output layer updates\n",
    "    output_weights_update = delta_output.T.dot(hidden_output)\n",
    "    output_biases_update = delta_output.sum(axis = 0)\n",
    "\n",
    "    # push back the delta to the hidden layer\n",
    "    delta_hidden = delta_output*output_weights*activation_deriv(hidden_linout)\n",
    "\n",
    "    # hidden layer updates\n",
    "    hidden_weights_update = delta_hidden.T.dot(X)\n",
    "    hidden_biases_update = delta_hidden.sum(axis = 0)\n",
    "\n",
    "    output_weights -= output_weights_update*learning_rate\n",
    "    output_biases -= output_biases_update*learning_rate\n",
    "\n",
    "    hidden_layer_weights -= hidden_weights_update*learning_rate\n",
    "    hidden_layer_biases -= hidden_biases_update*learning_rate\n",
    "\n",
    "print (t)    \n",
    "print (predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1M9TpbXoac2L"
   },
   "source": [
    "# ANN Regression Example using sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B1dFO-DUac2L",
    "outputId": "54c85652-0b18-4830-9607-098a5f5ef8dd"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\enh\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:614: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.4162338898076593"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "X, y = make_regression(n_samples=200, random_state=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    random_state=1)\n",
    "regr = MLPRegressor(random_state=1, max_iter=500).fit(X_train, y_train)\n",
    "regr.predict(X_test[:2])\n",
    "regr.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tuuo3te-ac2L"
   },
   "source": [
    "# Regression with a deep neural network (DNN) using keras\n",
    "In the previous section, you implemented two linear models for single and multiple inputs.\n",
    "\n",
    "Here, you will implement single-input and multiple-input DNN models.\n",
    "\n",
    "The code is basically the same except the model is expanded to include some \"hidden\" non-linear layers. The name \"hidden\" here just means not directly connected to the inputs or outputs.\n",
    "\n",
    "These models will contain a few more layers than the linear model:\n",
    "\n",
    "* The normalization layer, as before (with `horsepower_normalizer` for a single-input model and `normalizer` for a multiple-input model).\n",
    "\n",
    "* Two hidden, non-linear, `Dense` layers with the ReLU (`relu`) activation function nonlinearity.\n",
    "\n",
    "* A linear `Dense` single-output layer.\n",
    "\n",
    "Both models will use the same training procedure so the `compile` method is included in the `build_and_compile_model` function below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kFlEKDYRac2M"
   },
   "outputs": [],
   "source": [
    "def build_and_compile_model(norm):\n",
    "  model = keras.Sequential([\n",
    "      norm,\n",
    "      layers.Dense(64, activation='relu'),\n",
    "      layers.Dense(64, activation='relu'),\n",
    "      layers.Dense(1)\n",
    "  ])\n",
    "\n",
    "  model.compile(loss='mean_absolute_error',\n",
    "                optimizer=tf.keras.optimizers.Adam(0.001))\n",
    "  return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GGa24A6Xac2M"
   },
   "source": [
    "# Keras Tutorial Overview\n",
    "\n",
    "There is not a lot of code required, but we are going to step over it slowly so that you will know how to create your own models in the future.\n",
    "\n",
    "The steps you are going to cover in this tutorial are as follows:\n",
    "\n",
    "* Load Data.\n",
    "* Define Keras Model.\n",
    "* Compile Keras Model.\n",
    "* Fit Keras Model.\n",
    "* Evaluate Keras Model.\n",
    "* Tie It All Together.\n",
    "* Make Predictions\n",
    "\n",
    "Keras is a powerful and easy-to-use free open source Python library for developing and evaluating deep learning models.\n",
    "\n",
    "It wraps the efficient numerical computation libraries Theano and TensorFlow and allows you to define and train neural network models in just a few lines of code.\n",
    "\n",
    "\n",
    "\n",
    "Kick-start your project with the book **Deep Learning With Python**, including step-by-step tutorials and the Python source code files for all examples.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1dJBVByyac2M",
    "outputId": "dd2452c6-8be6-49d2-a230-65c03ce40c34"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ellipsis"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first neural network with keras tutorial\n",
    "from numpy import loadtxt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.utils.vis_utils import plot_model\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0dAUFIqTac2M",
    "outputId": "2395fc6f-bf93-412b-a34e-3ef204bbcdc5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of       6  148  72  35    0  33.6  0.627  50  1\n",
       "0     1   85  66  29    0  26.6  0.351  31  0\n",
       "1     8  183  64   0    0  23.3  0.672  32  1\n",
       "2     1   89  66  23   94  28.1  0.167  21  0\n",
       "3     0  137  40  35  168  43.1  2.288  33  1\n",
       "4     5  116  74   0    0  25.6  0.201  30  0\n",
       "..   ..  ...  ..  ..  ...   ...    ...  .. ..\n",
       "762  10  101  76  48  180  32.9  0.171  63  0\n",
       "763   2  122  70  27    0  36.8  0.340  27  0\n",
       "764   5  121  72  23  112  26.2  0.245  30  0\n",
       "765   1  126  60   0    0  30.1  0.349  47  1\n",
       "766   1   93  70  31    0  30.4  0.315  23  0\n",
       "\n",
       "[767 rows x 9 columns]>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "...\n",
    "import pandas as pd\n",
    "# load the dataset\n",
    "dataset = pd.read_csv('pima-indians-diabetes.data.csv', delimiter=',')\n",
    "dataset.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gxCS5X2Uac2M",
    "outputId": "a487a991-f707-4c6d-97a6-d8bc739ddfb9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of       6  148  72  35    0  33.6  0.627  50\n",
       "0     1   85  66  29    0  26.6  0.351  31\n",
       "1     8  183  64   0    0  23.3  0.672  32\n",
       "2     1   89  66  23   94  28.1  0.167  21\n",
       "3     0  137  40  35  168  43.1  2.288  33\n",
       "4     5  116  74   0    0  25.6  0.201  30\n",
       "..   ..  ...  ..  ..  ...   ...    ...  ..\n",
       "762  10  101  76  48  180  32.9  0.171  63\n",
       "763   2  122  70  27    0  36.8  0.340  27\n",
       "764   5  121  72  23  112  26.2  0.245  30\n",
       "765   1  126  60   0    0  30.1  0.349  47\n",
       "766   1   93  70  31    0  30.4  0.315  23\n",
       "\n",
       "[767 rows x 8 columns]>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = dataset.iloc[:,:-1]\n",
    "X.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 421
    },
    "id": "79S3awjwac2M",
    "outputId": "a516cd75-82f0-4917-aa0b-52893eedba5e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>762</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>765</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>767 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     1\n",
       "0    0\n",
       "1    1\n",
       "2    0\n",
       "3    1\n",
       "4    0\n",
       "..  ..\n",
       "762  0\n",
       "763  0\n",
       "764  0\n",
       "765  1\n",
       "766  0\n",
       "\n",
       "[767 rows x 1 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = dataset.iloc[:,[8]]\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "oGMo1Be-ac2N"
   },
   "outputs": [],
   "source": [
    "# define the keras model\n",
    "import numpy as np\n",
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=8, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "# compile the keras model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# fit the keras model on the dataset\n",
    "plot_model(model, to_file='model_plot1.png', show_shapes=True, show_layer_names=True)\n",
    "model.fit(X, y, epochs=150, batch_size=10, verbose=0)\n",
    "# make class predictions with the model\n",
    "predictions = (model.predict(X) > 0.5).astype(int)\n",
    "# summarize the first 5 cases\n",
    "predictions.shape\n",
    "predictions = predictions.flatten()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_5-Nnx9bhGbl",
    "outputId": "c50eba9b-84ba-4ec0-a9bc-afe757746329"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(767,)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "id": "xrHzrpE_iI7Z"
   },
   "outputs": [],
   "source": [
    "y = y.to_numpy().flatten()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Nylp1x-GhNF8",
    "outputId": "d506eb28-fca0-46b5-f88d-ade660b3038a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "E4HBB7oxbtXE",
    "outputId": "3dda66c7-d80f-4240-a3c8-eed565e6762a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0\n",
      "1 1\n",
      "0 0\n",
      "1 1\n",
      "0 0\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "\tprint( predictions[i], y[i])\n",
    "  \n",
    "\t  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 312
    },
    "id": "DIYhCSZAcj-K",
    "outputId": "70edb8a4-086c-4926-9d8a-055eecbcc2b8"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAbQAAAEnCAYAAADBxrarAAAABmJLR0QA/wD/AP+gvaeTAAAgAElEQVR4nOzde1RTZ9Y/8G8gCSGQAMq1IgoBtSLVUu0I1dG+tMxUXkGkClN1XuvPLrS1iLdRvFBFRC0OsrAwLivDu0ZcCl4WWpW2y3ZhX6eO046iFKuiBVEpBazIXW7790dLagyXBBICx/1ZK394znPOs3NOyPacPOfZIiIiMMYYY4OcmakDYIwxxgyBExpjjDFB4ITGGGNMEDihMcYYEwTx0wsuXLiApKQkU8TCGGOM6WTlypXw8/PTWKZ1hXb37l0cPXq034JijBnOvXv3+O+3F44ePYp79+6ZOgymo6NHj+Lu3btay7Wu0DocOXLEqAExxgwvOzsb4eHh/PerJ5FIhBUrVmDu3LmmDoXpQCQSdbqcf0NjjDEmCJzQGGOMCQInNMYYY4LACY0xxpggcEJjjDEmCJzQGGNazpw5AxsbG3zyySemDmVAWrJkCUQikfo1f/58rTZnz55FTEwMjh07Bg8PD3XbBQsWaLUNDAyEQqGAubk5vL29cenSpf54G33W3t6O3bt3w9/fX2vdyZMnsXPnTrS1tWksz8nJ0Th29vb2BouHExpjTAsX4ejZkCFDkJubixs3biA9PV1j3QcffICUlBSsX78eYWFh+OGHH6BSqTB06FBkZmbi9OnTGu0///xzHDlyBDNnzkRhYSF8fX378630SlFREX7/+99j5cqVaGho0FofHBwMmUyGgIAAVFdXq5eHhITg3r17+OqrrzBjxgyDxsQJjTGmJSgoCI8ePcLMmTNNHQoaGxs7vQIwNUtLS/zxj3/EqFGjYGFhoV6+Y8cOHD58GNnZ2VAoFBrbpKSkwMzMDJGRkXj06FF/h2wwV65cwbp167B06VJMmDChy3bLly/H+PHjMWPGDLS2tgL45RmyYcOGYerUqfDy8jJoXJzQGGMDWnp6OioqKkwdhk5u3bqFTZs2YcuWLZDJZFrr/f39ER0djfv372P16tUmiNAwxo8fj2PHjmHevHkaybwzmzdvRn5+PpKTk40eFyc0xpiG8+fPw83NDSKRCB999BEAIC0tDVZWVpDL5Thx4gTeeOMNKJVKuLq64tChQ+ptU1JSIJPJ4OjoiCVLlsDFxQUymQz+/v64ePGiul1UVBSkUimcnZ3Vy9577z1YWVlBJBKhqqoKABAdHY1Vq1bh9u3bEIlE8PT0BAB8+umnUCqV2LZtW38cEp2lpKSAiBAcHNxlm/j4eIwaNQr79+/H2bNnu90fESEpKQnPP/88LCwsYGdnh1mzZuH69evqNrqeGwBoa2tDbGws3NzcYGlpiRdeeAFZWVl9e9M9sLOzw7Rp05CcnGz0W9mc0BhjGqZMmYKvv/5aY9m7776LFStWoLGxEQqFAllZWbh9+zY8PDzwzjvvoKWlBcAviWrhwoVoaGjA8uXLUVJSgkuXLqG1tRWvv/66ev69lJQUrWmmUlNTsWXLFo1lycnJmDlzJlQqFYgIt27dAgD1QIP29najHIPeOn36NEaPHg25XN5lG0tLS/zv//4vzMzM8M4776C+vr7Ltps3b0ZMTAw2bNiAiooKfPXVV7h79y6mTp2Kn376CYDu5wYA1q1bhw8//BC7d+/Gjz/+iJkzZ+Ktt97Ct99+a7iD0IkXX3wR9+/fx5UrV4zaDyc0xphe/P39oVQq4eDggIiICNTX16O0tFSjjVgsVl9VjB07FmlpaaitrUVGRoZBYggKCkJNTQ02bdpkkP0ZQn19PYqLi6FSqXps6+fnhxUrVqCkpATr1q3rtE1jYyOSkpIwe/ZszJ8/HzY2NvDx8cHevXtRVVWFffv2aW3T3blpampCWloaQkNDERYWBltbW2zcuBESicRg56UrHb+VFRQUGLUfTmiMsV6TSqUAoHEV0JmJEydCLpdr3CoTmoqKChBRt1dnT4qPj8fo0aORmpqK8+fPa60vLCxEXV0dJk6cqLF80qRJkEqlGrdwO/P0ublx4wYaGhowbtw4dRtLS0s4Ozsb/bx0HJOOq0pj4YTGGOsXFhYWqKysNHUYRtPU1AQAPQ6S6CCTyZCRkQGRSIRFixahsbFRY33HUHdra2utbW1tbVFbW6tXfB23Njdu3KjxHNidO3c6HXZvSJaWlgB+O0bGwgmNMWZ0LS0tqK6uhqurq6lDMZqOL+2nHyTujp+fH1auXImioiJs3bpVY52trS0AdJq4enMsHRwcAAC7d+8GEWm8Lly4oNe+9NXc3Azgt2NkLJzQGGNGl5eXByLC5MmT1cvEYnGPtyoHE0dHR4hEIr2fL9u6dSvGjBmDy5cvaywfN24crK2ttQZsXLx4Ec3NzXjppZf06mf48OGQyWTIz8/XaztD6DgmTk5ORu2HExpjzODa29vx8OFDtLa24urVq4iOjoabmxsWLlyobuPp6Ymff/4ZOTk5aGlpQWVlJe7cuaO1ryFDhqCsrAwlJSWora1FS0sLcnNzB9ywfblcDg8PD70rX3fcejQ3N9davmrVKhw/fhyZmZmoqalBQUEBli5dChcXF0RGRurdz9tvv41Dhw4hLS0NNTU1aGtrw7179/Djjz8CACIiIuDk5GTwqbc6jomPj49B96uFnpKVlUWdLGaMDQKG+Pvds2cPOTs7EwCSy+UUHBxMqampJJfLCQB5eXnR7du3ad++faRUKgkAjRgxgm7evElERJGRkSSRSGjYsGEkFotJqVTSrFmz6Pbt2xr9PHjwgF599VWSyWTk7u5O77//Pq1Zs4YAkKenJ5WWlhIR0aVLl2jEiBFkaWlJU6ZMofLycjpz5gwpFAqKj4/v03vtAICysrJ0bh8ZGUnDhg3TWh4VFUUSiYQaGhrUy44fP04qlYoAkL29PS1btqzTfa5Zs4ZCQkI0lrW3t1NiYiJ5eXmRRCIhOzs7Cg0NpRs3bqjb6HNuHj9+TGvXriU3NzcSi8Xk4OBAYWFhVFhYSEREoaGhBIBiY2O7ff8XLlygV155hVxcXAgAASBnZ2fy9/enc+fOabUPCgqiYcOGUXt7u8by5cuX09ChQ7vtqzNdnS9OaIwJyED4+42MjKQhQ4aYNAZ9GSqhFRUVkVgspgMHDhgyvH7T1tZGU6dOpfT0dIPts6qqimQyGe3atUtrnaETGt9yZIwZnD4DIwarxsZGfPbZZygqKlIPevD09ERcXBzi4uJQV1dn4gj109bWhpycHNTW1iIiIsJg+928eTMmTJiAqKgoAL/MflJWVobz58+rH5Q3FE5ojDHWCz///LN6cuJFixapl8fExGDOnDmIiIgYVBMQ5+Xl4dixY8jNzdX5WbqeJCUlIT8/H2fOnIFEIgEAnDhxQj058dNVB/rKKAlt8eLFUCgUEIlEJhlRY0jd1fsBfnk48slnOjpeTz68qA8h1KH617/+heeffx5mZmYQiURwcnJCfHy8qcPS8HSNKmdn505rWjH9rF+/HhkZGXj06BHc3d1x9OhRU4dkFHv37tUY9p6Zmamxftu2bYiKisL27dtNFKH+AgICcPDgQY35NfvixIkTePz4MfLy8mBnZ6dePmvWLI1j1zFvpyGIDbanJ+zfvx+vvfYa/vSnPxlj9/2mqKgIb7/9Nv75z39i/Pjx/dInCaAO1eTJk/H999/jj3/8Iz777DPcuHFD/UzNQBEWFoawsDB4enqiqqoK5eXlpg5JEBISEpCQkGDqMAaEwMBABAYGmjoMkwkJCUFISEi/9sm3HLuga70fADhw4IDWg4rfffddr/rlOlTGIaT3whjrnNESmkgkMtau+4U+9X6EajDVoeqJkN4LY6xzBkloRITExESMHj0aFhYWsLGxwZo1a7TadVeLR5+aPufOncPLL78MuVwOpVIJHx8f1NTU9NjHQCf0OlQD7b3o6//+7/8wduxY2NjYQCaTwcfHB5999hmAX3437vg9TqVSqWd9ePvttyGXy2FjY4OTJ08C6P4z+uGHH0Iul0OhUKCiogKrVq3CsGHDcOPGjV7FzNgz5elx/L15jmXDhg0kEonor3/9Kz18+JAaGhooNTWVANDly5fV7VavXk0WFhZ09OhRevjwIa1fv57MzMzom2++Ue8HAH3xxRf06NEjqqiooKlTp5KVlRU1NzcTEVFdXR0plUrauXMnNTY2Unl5Oc2ePZsqKyt16qM3fve739H48eM7Xbd161ZydXUlW1tbkkgkNHLkSAoJCaF///vfverr7t27BID27NmjXqbLcSH65dkYKysrunbtGjU1NVFhYSFNmjSJFAqF+iFVIqJ58+aRk5OTRr+JiYkEQH0ciYjCwsJIpVJptDt16hQpFAqKi4vr8b384Q9/IAD08OHDAfleiIhUKhXZ2Nj0+F6IiI4cOUKbN2+mn3/+mR48eECTJ0/WeIYmLCyMzM3N6f79+xrbvfXWW3Ty5En1v3X9O1i+fDnt2bOHZs+eTd9//71OMQ6E59AGI+j5HBozra7OV5+v0BobG7F792689tprWLlyJWxtbWFpaYkhQ4ZotNOnFk93NX1KSkpQU1MDb29vyGQyODk54dixY7C3tzdJvZ//+Z//wcmTJ3H37l3U1dXh0KFDKC0txbRp01BYWGjQvoRUh2ogvBd9vfnmm/jggw9gZ2eHIUOGIDg4GA8ePFDPIL906VK0tbVpxFdTU4NvvvkGM2bMAKDf38GOHTuwbNkyHDt2DGPGjOm/N8rYINXnhHbr1i00NDQgICCg23a9rcXzdE0fDw8PODo6Yv78+di8eTNKSkr63EdfDB8+HC+++CKsra0hlUoxefJkZGRkoLGxEampqUbpExBWHarB+l46nqvpeIj4v/7rvzBq1Cj8/e9/V49WPXz4MCIiItTz9PXXZ7SzR0n41fULAMLDw00eB790P1+d6fOw/Y5JJztKE3TlyVo8Gzdu1Fjn4uKic3+Wlpb48ssvsW7dOmzbtg1xcXGYO3cuMjIyDNZHX/n4+MDc3Bw3b97stz67I6Q6VKZ8L6dPn0ZiYiIKCwtRU1OjlYBFIhGWLFmClStX4osvvsBrr72Gf/zjHzh48KC6TX99RgfL78YDRXh4OKKjo+Hn52fqUJgOwsPDO13e54Qmk8kAAI8fP+623ZO1eKKjo/vUp7e3Nz755BNUVlYiKSkJO3bsgLe3t3q6FkP00Rft7e1ob28fEKMjhVSHqr/fy1dffYX//Oc/WLFiBUpLSxEaGorZs2fj73//O5577jns2bMHf/nLXzS2WbhwIdavX4/9+/dj+PDhUCqVGDFihHq9If8OujN37lyj7VuIwsPD4efnx8dtkOgqofX5luO4ceNgZmaGc+fOddvOULV4ysrKcO3aNQC/fDls374dvr6+uHbtmknq/fzhD3/QWvbNN9+AiAbE//aEVIeqv9/Lf/7zH1hZWQEACgoK0NLSgnfffRceHh6QyWSd3vqws7NDeHg4cnJysGvXLrzzzjsa601Zk4oxoetzQnNwcEBYWBiOHj2K9PR01NTU4OrVq9i3b59GO11q8eiirKwMS5YswfXr19Hc3IzLly/jzp07mDx5ssH60Mf9+/dx+PBhVFdXo6WlBRcuXMDixYvh5uaGpUuXGqXP7gipDpWx30tXWlpa8NNPPyEvL0+d0Nzc3AAAZ8+eRVNTE4qKijQeIXjS0qVL8fjxY5w6dUrrAXlTfEYZe2Y8PeyxN8N+a2trafHixTR06FCytramKVOmUGxsLAEgV1dXunLlChF1X4tH15o+JSUl5O/vT3Z2dmRubk7PPfccbdiwgVpbW3vsQx+61vtZtWoVqVQqsrKyIrFYTK6urvTOO+9QWVmZXv0RCacO1b/+9S/y9vYmMzMz9XHbtm3bgHovf/vb39Q1qrp7HT9+XN3X2rVraciQIWRra0tz5syhjz76iACQSqXSeJSAiOjFF1+kmJiYTo9Pd5/RnTt3kqWlJQGg4cOH612GhIft9w542P6g0tX54npoAjIY61B1ZbC/lxkzZtAPP/zQ7/3y32/vcEIbXLo6XzyXo8AIqQ7VYHovT97CvHr1KmQyGdzd3U0YEWPPnmcmoV2/fl2n5xsMWdjOlP2y/rV27VoUFRXh5s2bePvtt7F161ZTh8SMaMmSJRp/v52VHjp79ixiYmK0ShUtWLBAq21gYCAUCgXMzc3h7e2NS5cu9cfb6LPuymudPHkSO3fu1PqPaU5Ojsaxs7e3N1xAT1+y8S2LwSkmJoakUikBoJEjR9KRI0dMHVKvDcb3smHDBjIzM6Phw4drTHPV3/jvt3eg5y3Hjlviubm5dOPGDWpqatJYHxsbSzNnzqSamhr1MpVKRUOHDiUAdOrUKa195ubmUkhISO/fRD+7efMmvfLKKwSgy6kBk5OTadq0aRrT37W3t9O9e/foq6++ohkzZmhMH6errs7XM3OFJnQJCQl4/PgxiAjFxcV48803TR1Srw3G9xIfH4+2tjaUlpYOiNI/ptQfpXoGQjkgS0tLdcXqJ5853bFjBw4fPozs7GwoFAqNbVJSUmBmZobIyMhBVc36abqW11q+fDnGjx+PGTNmoLW1FcAvExB0VKz28vIyaFyc0BhjBtUfpXoGajmgW7duYdOmTdiyZYt60okn+fv7Izo6Gvfv38fq1atNEKFh6FNea/PmzcjPz0dycrLR4+KExtgzjoiQlJSkngjazs4Os2bN0phbsi+legZDaSNDSUlJAREhODi4yzbx8fEYNWoU9u/fj7Nnz3a7P13OjT6lt0xRXsvOzg7Tpk1DcnKyeo5To3n6HiTfg2ds8OrN329sbCxJpVI6cOAAVVdX09WrV8nX15fs7e2pvLxc3a4vpXoGWmmjp6EXv6ENGzZMa7mHhweNHTu2021UKhUVFxcTEdHXX39NZmZmNHLkSKqrqyOizn9D0/Xc6FqWqb/La3WIiYnRKidGRLR8+XL+DY0xZhiNjY1ISkrC7NmzMX/+fNjY2MDHxwd79+5FVVWV1ow/fTFYShv1Vn19PYqLi6FSqXps6+fnhxUrVqCkpATr1q3rtE1vzk13ZZlMUV6rQ8dvZQUFBUbthxMaY8+wwsJC1NXVYeLEiRrLJ02aBKlU2uX0XoYw0MoB9VVFRQWICHK5XKf28fHxGD16NFJTU3H+/Hmt9X09N0+XZTJFea0OHcfkp59+Mmo/nNAYe4ZVV1cDAKytrbXW2draora21qj9C6m0UVNTEwDoXGVDJpMhIyMDIpEIixYtQmNjo8Z6Q5+bJ0sXPfkc2J07d9DQ0KDXvvRlaWkJ4LdjZCyc0Bh7htna2gJAp1+Oxi7VI6TSRsBvX9r6zHDj5+eHlStXoqioSOthfEOfmydLF9Ev0x6qXxcuXNBrX/pqbm4G8NsxMhZOaIw9w8aNGwdra2t8++23GssvXryI5uZmvPTSS+plhi7VI6TSRgDg6OgIkUik9/NlW7duxZgxY3D58mWN5fqcG12YsnRRxzFxcnIyaj+c0Bh7hslkMqxatQrHjx9HZmYmampqUFBQgKVLl8LFxQWRkZHqtn0t1SOk0kadkcvl8PDwwL179/TaruPWo7m5udZyXc+Nrv30VLooIiICTk5OBp96q+OY+Pj4GHS/Wp4e9sjD9hkbvHrz99ve3k6JiYnk5eVFEomE7OzsKDQ0lG7cuKHRri9lhwZKaaOuwEDD9qOiokgikVBDQ4N62fHjx9Wliuzt7WnZsmWd7nPNmjVaw/Z1OTf6lGXqqbxWaGgoAaDY2Nhu37+u5bU6BAUF0bBhw6i9vV1juaGH7XNCY0xABurf70AvB2SohFZUVERisVjvOnYDRVtbG02dOpXS09MNts+qqiqSyWS0a9curXX8HBpjbFAaTOWAdNHY2IjPPvsMRUVF6kEPnp6eiIuLQ1xcHOrq6kwcoX7a2tqQk5OD2tpag1b/2Lx5MyZMmICoqCgAv8x+UlZWhvPnz+PWrVsG6wfg39AYY6xXfv75Z/XkxIsWLVIvj4mJwZw5cxARETGoJiDOy8vDsWPHkJubq/OzdD1JSkpCfn4+zpw5A4lEAgA4ceKEenLi06dPG6SfDpzQGGNGtX79emRkZODRo0dwd3fH0aNHTR1Sn+3du1dj2HtmZqbG+m3btiEqKgrbt283UYT6CwgIwMGDBzXm0uyLEydO4PHjx8jLy4OdnZ16+axZszSOXcccnYYgNtieGGOsEwkJCUhISDB1GP0uMDAQgYGBpg7DZEJCQhASEtKvffIVGmOMMUHghMYYY0wQOKExxhgTBE5ojDHGBKHLQSHZ2dn9GQdjzAA6Jpnlv1/9GXuCXtYPnn7SumOmAX7xi1/84he/Buqrs5lCRL9OI8IYM5K5c+cC4KsmxoyNf0NjjDEmCJzQGGOMCQInNMYYY4LACY0xxpggcEJjjDEmCJzQGGOMCQInNMYYY4LACY0xxpggcEJjjDEmCJzQGGOMCQInNMYYY4LACY0xxpggcEJjjDEmCJzQGGOMCQInNMYYY4LACY0xxpggcEJjjDEmCJzQGGOMCQInNMYYY4LACY0xxpggcEJjjDEmCJzQGGOMCQInNMYYY4LACY0xxpggcEJjjDEmCJzQGGOMCQInNMYYY4LACY0xxpggcEJjjDEmCJzQGGOMCQInNMYYY4LACY0xxpggcEJjjDEmCCIiIlMHwZhQHDx4EOnp6Whvb1cvKy4uBgC4u7url5mZmeH//b//h3nz5vV7jIwJFSc0xgzo6tWrGD9+vE5tr1y5ghdeeMHIETH27OCExpiBjRkzBjdu3Oi2jaenJ4qKivopIsaeDfwbGmMGtmDBAkgkki7XSyQSvP322/0YEWPPBr5CY8zAfvjhB3h6eqK7P62ioiJ4enr2Y1SMCR9foTFmYB4eHvD19YVIJNJaJxKJMHHiRE5mjBkBJzTGjODPf/4zzM3NtZabm5vjz3/+swkiYkz4+JYjY0ZQUVEBFxcXjeH7wC/D9cvKyuDk5GSiyBgTLr5CY8wIHB0dMW3aNI2rNHNzc0yfPp2TGWNGwgmNMSNZsGCB1sCQBQsWmCgaxoSPbzkyZiQ1NTVwcHBAc3MzgF+G61dUVMDW1tbEkTEmTHyFxpiRKJVK/PGPf4RYLIZYLMaMGTM4mTFmRJzQGDOi+fPno62tDW1tbTxvI2NGxrccGTOipqYm2Nvbg4hQVVUFS0tLU4fEmGAJNqFlZ2cjPDzc1GEwxtiAkpWVhblz55o6DKMQmzoAY8vKyjJ1CEyALly4gOTkZJ0+X/n5+RCJRDrPwi9k4eHhiI6Ohp+fn6lDeSYJ/T/5gk9oQv2fCDO95ORknT5fs2fPBgCIxYL/c+tReHg4/Pz8+O/SRDihMcb6hBMZY/2DRzkyxhgTBE5ojDHGBIETGmOMMUHghMYYY0wQOKExZkJnzpyBjY0NPvnkE1OHMuCdPXsWMTExOHbsGDw8PCASiSASiTqd8DkwMBAKhQLm5ubw9vbGpUuXTBCx/trb27F79274+/trrTt58iR27tyJtrY2E0Q2OHBCY8yEBDqvgcF98MEHSElJwfr16xEWFoYffvgBKpUKQ4cORWZmJk6fPq3R/vPPP8eRI0cwc+ZMFBYWwtfX10SR666oqAi///3vsXLlSjQ0NGitDw4OhkwmQ0BAAKqrq00Q4cDHCY0xEwoKCsKjR48wc+ZMU4eCxsbGTq8MTG3Hjh04fPgwsrOzoVAoNNalpKTAzMwMkZGRePTokYki7LsrV65g3bp1WLp0KSZMmNBlu+XLl2P8+PGYMWMGWltb+zHCwYETGmMMAJCeno6KigpTh6Hh1q1b2LRpE7Zs2QKZTKa13t/fH9HR0bh//z5Wr15tgggNY/z48Th27BjmzZsHCwuLbttu3rwZ+fn5SE5O7qfoBg9OaIyZyPnz5+Hm5gaRSISPPvoIAJCWlgYrKyvI5XKcOHECb7zxBpRKJVxdXXHo0CH1tikpKZDJZHB0dMSSJUvg4uICmUwGf39/XLx4Ud0uKioKUqkUzs7O6mXvvfcerKysIBKJUFVVBQCIjo7GqlWrcPv2bYhEInh6egIAPv30UyiVSmzbtq0/DomWlJQUEBGCg4O7bBMfH49Ro0Zh//79OHv2bLf7IyIkJSXh+eefh4WFBezs7DBr1ixcv35d3UbXcwAAbW1tiI2NhZubGywtLfHCCy8Yfbo9Ozs7TJs2DcnJyXzL+mkkUFlZWSTgt8dMzFCfr7t37xIA2rNnj3rZhg0bCAB98cUX9OjRI6qoqKCpU6eSlZUVNTc3q9tFRkaSlZUVXbt2jZqamqiwsJAmTZpECoWCSktL1e3mzZtHTk5OGv0mJiYSAKqsrFQvCwsLI5VKpdHu1KlTpFAoKC4urs/vlYgIAGVlZenc3sPDg8aOHdvpOpVKRcXFxURE9PXXX5OZmRmNHDmS6urqiIgoNzeXQkJCNLaJjY0lqVRKBw4coOrqarp69Sr5+vqSvb09lZeXq9vpeg5Wr15NFhYWdPToUXr48CGtX7+ezMzM6JtvvtH5PT7td7/7HY0fP77bNjExMQSALl++rNe+9T3+gw1foTE2QPn7+0OpVMLBwQERERGor69HaWmpRhuxWKy+2hg7dizS0tJQW1uLjIwMg8QQFBSEmpoabNq0ySD700d9fT2Ki4uhUql6bOvn54cVK1agpKQE69at67RNY2MjkpKSMHv2bMyfPx82Njbw8fHB3r17UVVVhX379mlt0905aGpqQlpaGkJDQxEWFgZbW1ts3LgREonEYMe/K15eXgCAgoICo/Yz2HBCY2wQkEqlAICWlpZu202cOBFyuVzjFtpgVVFRASKCXC7XqX18fDxGjx6N1NRUnD9/Xmt9YWEh6urqMHHiRI3lkyZNglQq1bhV25mnz8GNGzfQ0NCAcePGqdtYWlrC2dnZ6Me/45j89NNPRu1nsOGExpjAWFhYoLKy0tRh9FlTUxMA9DhIooNMJkNGRgZEIhEWLVqExsZGjfUdQ92tra21trW1tUVtba1e8dXX1wMANm7cqH4mTrUKU+8AACAASURBVCQS4c6dO50OuzekjkKxHceI/YITGmMC0tLSgurqari6upo6lD7r+NLW50FiPz8/rFy5EkVFRdi6davGOltbWwDoNHH15pg5ODgAAHbv3g0i0nhduHBBr33pq7m5GQC4AvpTOKExJiB5eXkgIkyePFm9TCwW93irciBydHSESCTS+/myrVu3YsyYMbh8+bLG8nHjxsHa2hrffvutxvKLFy+iubkZL730kl79DB8+HDKZDPn5+XptZwgdx8TJyanf+x7IOKExNoi1t7fj4cOHaG1txdWrVxEdHQ03NzcsXLhQ3cbT0xM///wzcnJy0NLSgsrKSty5c0drX0OGDEFZWRlKSkpQW1uLlpYW5ObmmmzYvlwuh4eHB+7du6fXdh23Hs3NzbWWr1q1CsePH0dmZiZqampQUFCApUuXwsXFBZGRkXr38/bbb+PQoUNIS0tDTU0N2tracO/ePfz4448AgIiICDg5ORl86q2OY+Lj42PQ/Q56phxiaUw8bJ8ZkyE+X3v27CFnZ2cCQHK5nIKDgyk1NZXkcjkBIC8vL7p9+zbt27ePlEolAaARI0bQzZs3ieiXYfsSiYSGDRtGYrGYlEolzZo1i27fvq3Rz4MHD+jVV18lmUxG7u7u9P7779OaNWsIAHl6eqqH+F+6dIlGjBhBlpaWNGXKFCovL6czZ86QQqGg+Pj4Pr3XDtBz2HhUVBRJJBJqaGhQLzt+/DipVCoCQPb29rRs2bJOt12zZo3WsP329nZKTEwkLy8vkkgkZGdnR6GhoXTjxg11G33OwePHj2nt2rXk5uZGYrGYHBwcKCwsjAoLC4mIKDQ0lABQbGxst+/zwoUL9Morr5CLiwsBIADk7OxM/v7+dO7cOa32QUFBNGzYMGpvb9ftQP5K3+M/2Aj2G58TGjOmgfD5ioyMpCFDhpg0Bn3p+4VaVFREYrGYDhw4YMSojKetrY2mTp1K6enpBttnVVUVyWQy2rVrl97bCj2h8S1HxgYxoc+87unpibi4OMTFxaGurs7U4eilra0NOTk5qK2tRUREhMH2u3nzZkyYMAFRUVEG26dQcELrxuLFi6FQKCASiUzyw68hdVeWAvjlGZ4nhx53vJ58xkZXT5f36HhJpVI4Ojpi+vTpSExMxMOHD/v6ttgzICYmBnPmzEFERMSgmoA4Ly8Px44dQ25urs7P0vUkKSkJ+fn5OHPmDCQSiUH2KSSc0Lqxf/9+fPzxx6YOo896KkthaE+W97CxsQERob29HRUVFcjOzoa7uzvWrl0Lb29vrRFnTDfr169HRkYGHj16BHd3dxw9etTUIRnVtm3bEBUVhe3bt5s6FJ0FBATg4MGDGvNo9sWJEyfw+PFj5OXlwc7OziD7FBqxqQNgxnXlyhXExcVh6dKlqK+v73Yy0wMHDmD+/PlGiUMkEsHW1hbTp0/H9OnTERQUhPDwcAQFBeHmzZuwsbExSr9ClZCQgISEBFOH0a8CAwMRGBho6jBMJiQkBCEhIaYOY0DjK7QeiEQiU4fQJ/qUpehPb775JhYuXIiKigrs3bvX1OEwxgSAE9oTiAiJiYkYPXo0LCwsYGNjgzVr1mi1665khD6lJ86dO4eXX34ZcrkcSqUSPj4+qKmp6bEPUzJkOZGOZ6Vyc3PVy57lY8sY6yMTj7I0mt4Mq96wYQOJRCL661//Sg8fPqSGhgZKTU3VKtPQU8kIXUpP1NXVkVKppJ07d1JjYyOVl5fT7Nmz1eU8+rssxdatW8nV1ZVsbW1JIpHQyJEjKSQkhP79739rtNOnnIhKpSIbG5su19fU1BAAGj58uHrZYDm2A2HY/mAEgQ8bH+iEfvwF+xep7xdOQ0MDyeVyev311zWWHzp0SCOhNTY2klwup4iICI1tLSws6N133yWi3750Gxsb1W06EuOtW7eIiOi7774jAHTq1CmtWHTpoze6S2ilpaV06dIlqq2tpcePH9OFCxfoxRdfJEtLS/ruu+961V9PCY2ISCQSka2tLRENrmPLCa13hP6FOtAJ/fjzoJBf3bp1Cw0NDQgICOi2XW9LRjxdesLDwwOOjo6YP38+li9fjoULF2LkyJF96qMvhg8fjuHDh6v/PXnyZGRkZGDChAlITU1FWlqawfvsGKSiVCoBDM5jm52drfc2zzpjT9zLnmGmzqjGou//oM+cOUMAtJ7of/oK7Z///Kd6apqnX5MnTyaizq8iPv74YwJA33//vXrZd999R//93/9NYrGYRCIRhYeHU0NDg0599IYulXCf1NbWRubm5hQQENCr/nq6Qrt06RIBoMDAQCIaXMe24/PFL34NtpeQr9B4UMivZDIZAODx48fdtjNkyQhvb2988sknKCsrw9q1a5GVlYVdu3aZtCzFk9rb29He3m600ZGffvopAOCNN94AMDiP7dP74Ff3LwDIysoyeRzP6kvoOKH9aty4cTAzM8O5c+e6bWeokhFlZWW4du0agF++yLdv3w5fX19cu3bNJGUp/vCHP2gt++abb0BE8PPzM3h/5eXl2L17N1xdXbFo0SIAwj22jLH+wQntVw4ODggLC8PRo0eRnp6OmpoaXL16Ffv27dNop0vJCF2UlZVhyZIluH79Opqbm3H58mXcuXMHkydPNlgf+rh//z4OHz6M6upqtLS04MKFC1i8eDHc3NywdOlSdTt9y4kQEerq6tDe3g4iQmVlJbKysvDKK6/A3NwcOTk56t/QhHpsGWP9hASqN6PQamtrafHixTR06FCytramKVOmUGxsLAEgV1dXunLlChF1XzJC19ITJSUl5O/vT3Z2dmRubk7PPfccbdiwgVpbW3vsQx+6lqVYtWoVqVQqsrKyIrFYTK6urvTOO+9QWVmZxv50KSdy8uRJeuGFF0gul5NUKiUzMzMCoB7R+PLLL1NcXBw9ePBAa9vBcmx5lGPvQOC/4Qx0Qj/+IiJh3ljNzs5GeHj4M3HfmPU//nz1jkgkQlZWFubOnWvqUJ5JQj/+fMuRMcaYIHBCG2SuX7/eaZmXp1+GrL/EGGODASe0QWbMmDE6Dc89fPiwqUNlzKDOnj2LmJgYrXp7CxYs0GobGBgIhUIBc3NzeHt749KlSyaIWHdxcXEYO3YslEolLCws4Onpib/85S8aRU1PnjyJnTt3Cr6oa19wQmOMDXgffPABUlJSsH79eo16e0OHDkVmZiZOnz6t0f7zzz/HkSNHMHPmTBQWFsLX19dEkevmyy+/xLJly1BSUoKqqiokJCQgOTkZc+bMUbcJDg6GTCZDQEAAqqurTRjtwMUJjbFBqrGxscsK5IOpj57s2LEDhw8fRnZ2NhQKhca6lJQUmJmZITIyclBVs36atbU1IiMjMWTIECgUCsydOxehoaH49NNPcffuXXW75cuXY/z48ZgxYwZaW1tNGPHAxAmNsUEqPT0dFRUVg76P7ty6dQubNm3Cli1b1LP5PMnf3x/R0dG4f/8+Vq9ebYIIDePUqVMwNzfXWGZvbw8AWlXmN2/ejPz8fCQnJ/dbfIMFJzTG+gkRISkpCc8//zwsLCxgZ2eHWbNmaUyKHBUVBalUCmdnZ/Wy9957D1ZWVhCJRKiqqgIAREdHY9WqVbh9+zZEIhE8PT2RkpICmUwGR0dHLFmyBC4uLpDJZPD398fFixcN0gdg2Jp4PUlJSQERITg4uMs28fHxGDVqFPbv34+zZ892uz9dzoE+dfeMWVvv/v37sLS0hLu7u8ZyOzs7TJs2DcnJyfzYyNP6/cm3fsIPvjJj6s3nKzY2lqRSKR04cICqq6vp6tWr5OvrS/b29lReXq5uN2/ePHJyctLYNjExkQCoa7oREYWFhZFKpdJoFxkZSVZWVnTt2jVqamqiwsJCmjRpEikUCiotLTVIH/rUxHsa9Hyw18PDg8aOHdvpOpVKRcXFxURE9PXXX5OZmRmNHDmS6urqiIgoNzeXQkJCNLbR9RzoUnePyDh1C4mI6uvrSaFQUFRUVKfrY2JiCNCs06gLfY//YMNXaIz1g8bGRiQlJWH27NmYP38+bGxs4OPjg71796KqqkprirW+EIvF6iuQsWPHIi0tDbW1tcjIyDDI/oOCglBTU4NNmzYZZH9dqa+vR3FxMVQqVY9t/fz8sGLFCpSUlGDdunWdtunNOfD394dSqYSDgwMiIiJQX1+P0tJSAEBTUxPS0tIQGhqKsLAw2NraYuPGjZBIJH0+1gkJCXBxcUF8fHyn6728vAAABQUFfepHaDihMdYPCgsLUVdXh4kTJ2osnzRpEqRSqcYtQUObOHEi5HK50WrpGUtFRQWICHK5XKf28fHxGD16NFJTU3H+/Hmt9X09B0/X3TNW3cLjx48jOzsbn332mdYgmA4dx+Snn37qdT9CxAmNsX7QMcza2tpaa52trS1qa2uN2r+FhQUqKyuN2oehNTU1AYDO5YtkMhkyMjIgEomwaNEiNDY2aqw39Dmor68HAGzcuFFjUoM7d+5oDeTQ1eHDh7Fjxw7k5eWpi9J2xtLSEsBvx4j9ghMaY/3A1tYWADr90qyuroarq6vR+m5paTF6H8bQ8aWtz4PEfn5+WLlyJYqKirB161aNdYY+B4aurbdnzx5kZmbiyy+/xHPPPddt2+bmZgC/HSP2C05ojPWDcePGwdraGt9++63G8osXL6K5uRkvvfSSeplYLFbf1jKEvLw8EBEmT55stD6MwdHRESKRSO/ny7Zu3YoxY8bg8uXLGsv1OQe6MFRtPSLC2rVrUVBQgJycnE6vIJ/WcUycnJz61LfQcEJjrB/IZDKsWrUKx48fR2ZmJmpqalBQUIClS5fCxcUFkZGR6raenp74+eefkZOTg5aWFlRWVuLOnTta+xwyZAjKyspQUlKC2tpadYJqb2/Hw4cP0draiqtXryI6Ohpubm5YuHChQfrQtyZeb8nlcnh4eODevXt6bddx6/Hp57r0OQe69tNTbb2IiAg4OTl1O/XWtWvX8OGHH+Ljjz+GRCLRmpd1165dWtt0HBMfHx+9YhY8E46wNCoets+MqTefr/b2dkpMTCQvLy+SSCRkZ2dHoaGhdOPGDY12Dx48oFdffZVkMhm5u7vT+++/T2vWrCEA5OnpqR5+f+nSJRoxYgRZWlrSlClTqLy8nCIjI0kikdCwYcNILBaTUqmkWbNm0e3btw3Why418boCPYeNR0VFkUQioYaGBvWy48ePk0qlIgBkb29Py5Yt63TbNWvWaA3b1+Uc6Fp3j6jn2nqhoaEEgGJjY7t8jwUFBepahZ29EhMTtbYJCgqiYcOGUXt7u87Hkkj4w/YF+43PCY0Z00D9fEVGRtKQIUNMHUaX9P1CLSoqIrFYTAcOHDBiVMbT1tZGU6dOpfT0dIPts6qqimQyGe3atUvvbYWe0PiWI2MCI6TZ2D09PREXF4e4uDiNmecHg7a2NuTk5KC2ttag5Zw2b96MCRMmICoqymD7FApOaIyxAS0mJgZz5sxBRETEoJqAOC8vD8eOHUNubq7Oz9L1JCkpCfn5+Thz5gwkEolB9ikknNAYE4j169cjIyMDjx49gru7O44ePWrqkAxm27ZtiIqKwvbt200dis4CAgJw8OBBjTkz++LEiRN4/Pgx8vLyYGdnZ5B9Co3Y1AEwxgwjISEBCQkJpg7DaAIDAxEYGGjqMEwmJCQEISEhpg5jQOMrNMYYY4LACY0xxpggcEJjjDEmCJzQGGOMCYLgB4XMmTPH1CEwAeqYeog/X/rbvXs3jhw5YuowmACJiIRZw/vChQtISkoydRiMqSfJffHFF00cCWPAypUr4efnZ+owjEKwCY2xgWLu3LkAgOzsbBNHwpiw8W9ojDHGBIETGmOMMUHghMYYY0wQOKExxhgTBE5ojDHGBIETGmOMMUHghMYYY0wQOKExxhgTBE5ojDHGBIETGmOMMUHghMYYY0wQOKExxhgTBE5ojDHGBIETGmOMMUHghMYYY0wQOKExxhgTBE5ojDHGBIETGmOMMUHghMYYY0wQOKExxhgTBE5ojDHGBIETGmOMMUHghMYYY0wQOKExxhgTBE5ojDHGBIETGmOMMUHghMYYY0wQOKExxhgTBE5ojDHGBIETGmOMMUHghMYYY0wQOKExxhgTBLGpA2BMSBoaGvD48WONZc3NzQCAhw8faiy3sLCAXC7vt9gYEzoREZGpg2BMKNLS0vDee+/p1DY1NRXvvvuukSNi7NnBCY0xA6qsrISLiwva2tq6bWdubo4ff/wRDg4O/RQZY8LHv6ExZkAODg4ICAiAubl5l23Mzc3x2muvcTJjzMA4oTFmYPPnz0d3Nz6ICPPnz+/HiBh7NvAtR8YMrLa2Fg4ODlqDQzpIpVJUVlZCqVT2c2SMCRtfoTFmYAqFAjNnzoREItFaJxaLERISwsmMMSPghMaYEcybNw+tra1ay9va2jBv3jwTRMSY8PEtR8aMoLm5Gfb29qitrdVYbm1tjaqqKlhYWJgoMsaEi6/QGDMCqVSKOXPmQCqVqpdJJBKEh4dzMmPMSDihMWYkb731lnqWEABoaWnBW2+9ZcKIGBM2vuXImJG0t7fD2dkZlZWVAAB7e3uUl5d3+4waY6z3+AqNMSMxMzPDW2+9BalUColEgnnz5nEyY8yIOKExZkR/+tOf0NzczLcbGesHgp1t/969e/j6669NHQZ7xhERhg4dCgAoLi5GSUmJaQNizzx/f3+4urqaOgyjEOxvaNnZ2QgPDzd1GIwxNqBkZWVh7ty5pg7DKAR7hdZBoPmamVjHf5h0+Xxdu3YNADB27FhjhzXgiUQiQX+hDnQikcjUIRiV4BMaY6bGiYyx/sGDQhhjjAkCJzTGGGOCwAmNMcaYIHBCY4wxJgic0BhjjAkCJzTGTOjMmTOwsbHBJ598YupQBryzZ88iJiYGx44dg4eHB0QiEUQiERYsWKDVNjAwEAqFAubm5vD29salS5dMELHu4uLiMHbsWCiVSlhYWMDT0xN/+ctfUFdXp25z8uRJ7Ny5E21tbSaMdGDjhMaYCfFzkrr54IMPkJKSgvXr1yMsLAw//PADVCoVhg4diszMTJw+fVqj/eeff44jR45g5syZKCwshK+vr4ki182XX36JZcuWoaSkBFVVVUhISEBycjLmzJmjbhMcHAyZTIaAgABUV1ebMNqBixMaYyYUFBSER48eYebMmaYOBY2NjfD39zd1GFp27NiBw4cPIzs7GwqFQmNdSkoKzMzMEBkZiUePHpkowr6ztrZGZGQkhgwZAoVCgblz5yI0NBSffvop7t69q263fPlyjB8/HjNmzOi0IvqzjhMaYwwAkJ6ejoqKClOHoeHWrVvYtGkTtmzZAplMprXe398f0dHRuH//PlavXm2CCA3j1KlTWpUY7O3tAQANDQ0ayzdv3oz8/HwkJyf3W3yDBSc0xkzk/PnzcHNzg0gkwkcffQQASEtLg5WVFeRyOU6cOIE33ngDSqUSrq6uOHTokHrblJQUyGQyODo6YsmSJXBxcYFMJoO/vz8uXryobhcVFQWpVApnZ2f1svfeew9WVlYQiUSoqqoCAERHR2PVqlW4ffs2RCIRPD09AQCffvoplEoltm3b1h+HREtKSgqICMHBwV22iY+Px6hRo7B//36cPXu22/0REZKSkvD888/DwsICdnZ2mDVrFq5fv65uo+s5AIC2tjbExsbCzc0NlpaWeOGFF5CVldW3N/2r+/fvw9LSEu7u7hrL7ezsMG3aNCQnJ/Mt66eRQGVlZZGA3x4zMUN9vu7evUsAaM+ePeplGzZsIAD0xRdf0KNHj6iiooKmTp1KVlZW1NzcrG4XGRlJVlZWdO3aNWpqaqLCwkKaNGkSKRQKKi0tVbebN28eOTk5afSbmJhIAKiyslK9LCwsjFQqlUa7U6dOkUKhoLi4uD6/VyIiAJSVlaVzew8PDxo7dmyn61QqFRUXFxMR0ddff01mZmY0cuRIqqurIyKi3NxcCgkJ0dgmNjaWpFIpHThwgKqrq+nq1avk6+tL9vb2VF5erm6n6zlYvXo1WVhY0NGjR+nhw4e0fv16MjMzo2+++Ubn99iZ+vp6UigUFBUV1en6mJgYAkCXL1/Wa7/6Hv/Bhq/QGBug/P39oVQq4eDggIiICNTX16O0tFSjjVgsVl9tjB07FmlpaaitrUVGRoZBYggKCkJNTQ02bdpkkP3po76+HsXFxVCpVD229fPzw4oVK1BSUoJ169Z12qaxsRFJSUmYPXs25s+fDxsbG/j4+GDv3r2oqqrCvn37tLbp7hw0NTUhLS0NoaGhCAsLg62tLTZu3AiJRNLn45+QkAAXFxfEx8d3ut7LywsAUFBQ0Kd+hIYTGmODgFQqBQC0tLR0227ixImQy+Uat9AGq4qKChAR5HK5Tu3j4+MxevRopKam4vz581rrCwsLUVdXh4kTJ2osnzRpEqRSqcat2s48fQ5u3LiBhoYGjBs3Tt3G0tISzs7OfTr+x48fR3Z2Nj777DOtQTAdOo7JTz/91Ot+hIgTGmMCY2FhgcrKSlOH0WdNTU0Afnk/upDJZMjIyIBIJMKiRYvQ2Niosb5jqLu1tbXWtra2tqitrdUrvvr6egDAxo0b1c/EiUQi3LlzR2sgh64OHz6MHTt2IC8vDyNHjuyynaWlJYDfjhH7BSc0xgSkpaUF1dXVgqhI3PGlrc+DxH5+fli5ciWKioqwdetWjXW2trYA0Gni6s0xc3BwAADs3r0bRKTxunDhgl77AoA9e/YgMzMTX375JZ577rlu2zY3NwP47RixX3BCY0xA8vLyQESYPHmyeplYLO7xVuVA5OjoCJFIpPfzZVu3bsWYMWNw+fJljeXjxo2DtbU1vv32W43lFy9eRHNzM1566SW9+hk+fDhkMhny8/P12u5pRIS1a9eioKAAOTk5nV5BPq3jmDg5OfWpb6HhhMbYINbe3o6HDx+itbUVV69eRXR0NNzc3LBw4UJ1G09PT/z888/IyclBS0sLKisrcefOHa19DRkyBGVlZSgpKUFtbS1aWlqQm5trsmH7crkcHh4euHfvnl7bddx6fPq5LplMhlWrVuH48ePIzMxETU0NCgoKsHTpUri4uCAyMlLvft5++20cOnQIaWlpqKmpQVtbG+7du4cff/wRABAREQEnJ6dup966du0aPvzwQ3z88ceQSCQaty9FIhF27dqltU3HMfHx8dErZsEz4QhLo+Jh+8yYDPH52rNnDzk7OxMAksvlFBwcTKmpqSSXywkAeXl50e3bt2nfvn2kVCoJAI0YMYJu3rxJRL8M25dIJDRs2DASi8WkVCpp1qxZdPv2bY1+Hjx4QK+++irJZDJyd3en999/n9asWUMAyNPTUz3E/9KlSzRixAiytLSkKVOmUHl5OZ05c4YUCgXFx8f36b12gJ7DxqOiokgikVBDQ4N62fHjx0mlUhEAsre3p2XLlnW67Zo1a7SG7be3t1NiYiJ5eXmRRCIhOzs7Cg0NpRs3bqjb6HMOHj9+TGvXriU3NzcSi8Xk4OBAYWFhVFhYSEREoaGhBIBiY2O7fI8FBQUEoMtXYmKi1jZBQUE0bNgwam9v1/lYEgl/2L5gv/E5oTFjGgifr8jISBoyZIhJY9CXvl+oRUVFJBaL6cCBA0aMynja2tpo6tSplJ6ebrB9VlVVkUwmo127dum9rdATGt9yZGwQE/rM656enoiLi0NcXJzGzPODQVtbG3JyclBbW4uIiAiD7Xfz5s2YMGECoqKiDLZPoeCE1o3FixdDoVBAJBL1+YdfU2tvb8fu3bu7nXy2paUFCQkJ8PT0hFQqha2tLcaNG4eSkhK9+nq6vEfHSyqVwtHREdOnT0diYiIePnzYx3fFngUxMTGYM2cOIiIiBtUExHl5eTh27Bhyc3N1fpauJ0lJScjPz8eZM2cgkUgMsk8h4YTWjf379+Pjjz82dRh9VlRUhN///vdYuXJlt8/HhIeH4x//+AcOHjyIhoYGfP/991CpVHr/z/jJ8h42NjYgIrS3t6OiogLZ2dlwd3fH2rVr4e3trTXijOlm/fr1yMjIwKNHj+Du7o6jR4+aOiSj2rZtG6KiorB9+3ZTh6KzgIAAHDx4UGMezb44ceIEHj9+jLy8PNjZ2Rlkn0IjNnUAzLiuXLmCuLg4LF26FPX19V1OZnr48GHk5OTgypUr6pFTLi4uOHHihEHiEIlEsLW1xfTp0zF9+nQEBQUhPDwcQUFBuHnzJmxsbAzSz7MiISEBCQkJpg6jXwUGBiIwMNDUYZhMSEgIQkJCTB3GgMZXaD0QiUSmDqFPxo8fj2PHjmHevHndzrjwt7/9Db6+vv02DPjNN9/EwoULUVFRgb179/ZLn4wxYeOE9gQiQmJiIkaPHg0LCwvY2NhgzZo1Wu26KxmhT+mJc+fO4eWXX4ZcLodSqYSPjw9qamp67MPQmpub8a9//QsTJkzosa0hy4l0PCuVm5urXia0Y8sY60cmHmVpNL0ZVr1hwwYSiUT017/+lR4+fEgNDQ2UmpqqVaahp5IRupSeqKurI6VSSTt37qTGxkYqLy+n2bNnq8t5GKMsxe9+9zsaP3681vLi4mICQBMmTKDp06eTs7MzWVhY0JgxY+ijjz7SeNZFn3IiKpWKbGxsulxfU1NDAGj48OHqZYPl2A6EYfuDEQQ+bHygE/rxF+xfpL5fOA0NDSSXy+n111/XWH7o0CGNhNbY2EhyuZwiIiI0trWwsKB3332XiH770m1sbFS36UiMt27dIiKi7777jgDQqVOntGLRpY/e6CqhdTzY+frrr9M///lPevDgAVVXV9O6desIAGVmZvaqv54SGhGRSCQiW1tbIhpcx5YTWu8I/Qt1oBP68edBIb+6desWGhoaEBAQ0G273paMeLr0hIeHBxwdHTF//nwsX74cCxcuVM+ubayyFF3p+G3N29tbY1j/li1b8Le//Q379u3DvHnzDN5vIrTTbwAACkhJREFUxyAVpVIJYHAe2zlz5ui9zbNu9+7dOHLkiKnDYALEv6H9qmNutI4ZtLtiqJIRlpaW+PLLLzFlyhRs27YNHh4eiIiIQGNjo1HKUnTHxcUFAFBVVaWxXCqVYsSIEbh9+7bB+wSAmzdvAgDGjBkDQJjHljHWf/gK7VcymQwA8Pjx427bPVkyIjo6uk99ent745NPPkFlZSWSkpKwY8cOeHt7q2cVMEQfurC2toaXlxeuXbumta61tdVoQ+o//fRTAMAbb7wBYHAeW77S0I9IJMKKFSswd+5cU4fyTBrso7Z7wldovxo3bhzMzMxw7ty5btsZqmREWVmZOoE4ODhg+/bt8PX1xbVr1wzWhz7Cw8Nx+fJl/PDDD+plDQ0NuHPnjlGG8peXl2P37t1wdXXFokWLAAj32DLG+gcntF85ODggLCwMR48eRXp6OmpqanD16lXs27dPo50uJSN0UVZWhiVLluD69etobm7G5cuXcefOHUyePNlgfehj5cqVGDFiBBYuXIjS0lI8ePAAa9euRWNjI9atW6dup285ESJCXV0d2tvbQUSorKxEVlYWXnnlFZibmyMnJ0f9G5pQjy1jrJ+YeFCK0fRmFFptbS0tXryYhg4dStbW1jRlyhSKjY0lAOTq6kpXrlwhou5LRuhaeqKkpIT8/f3Jzs6OzM3N6bnnnqMNGzZQa2trj33o48KFC/TKK6+Qi4uLuhyFs7Mz+fv707lz5zTa3r17l/70pz+RnZ0dWVhY0Msvv0y5ubkabXQpJ3Ly5El64YUXSC6Xk1QqJTMzMwKgHtH48ssvU1xcHD148EBr28FybHmUY+9A4KPsBjqhH38RURdzIQ1y2dnZCA8P73KqJ8b6gj9fvSMSiZCVlcW/oZmI0I8/33JkjDEmCJzQBpnr169rlWXp7GXI+kuMDQRnz55FTEyMVnmiBQsWaLUNDAyEQqGAubk5vL29cenSJRNErL/uyjydPHkSO3fuFHwNvL7ghDbIjBkzBvTLDC/dvg4fPmzqUBkzmA8++AApKSlYv369RnmioUOHIjMzE6dPn9Zo//nnn+PIkSOYOXMmCgsL4evra6LIdddTmafg4GDIZDIEBASgurraBBEOfJzQGBukGhsbuy3YOlj66MmOHTtw+PBhZGdnQ6FQaKxLSUmBmZkZIiMjB1Xxz6dduXIF69atw9KlS7udJHz58uUYP348ZsyYgdbW1n6McHDghMbYIJWeno6KiopB30d3bt26hU2bNmHLli3qyQ+e5O/vj+joaNy/fx+rV682QYSGoWuZJwDYvHkz8vPzkZyc3E/RDR6c0BjrJ0SEpKQkPP/887CwsICdnR1mzZqlMYdkVFQUpFKpRpXj9957D1ZWVhCJROrpyaKjo7Fq1Srcvn0bIpEInp6eSElJgUwmg6OjI5YsWQIXFxfIZDL4+/vj4sWLBukDMGwJoZ6kpKSAiBAcHNxlm/j4eIwaNQr79+/H2bNnu92fLudAnzJFpihFZGdnh2nTpiE5OZlH2T6t3x8U6Cf8nBAzpt58vmJjY0kqldKBAweourqarl69Sr6+vmRvb0/l5eXqdvPmzSMnJyeNbRMTEwmAugQOEVFYWBipVCqNdpGRkWRlZUXXrl2jpqYmKiwspEmTJpFCoaDS0lKD9KFPCaGnQc/noDw8PGjs2LGdrlOpVFRcXExERF9//TWZmZnRyJEjqa6ujoiIcnNzKSQkRGMbXc+BLmWKiPq3zNOTYmJitMpa6ULf4z/Y8BUaY/2gsbERSUlJmD17NubPnw8bGxv4+Phg7969qKqq0pqRpi/EYrH6CmTs2LFIS0tDbW0tMjIyDLL/oKAg1NTUYNOmTQbZX1fq6+tRXFwMlUrVY1s/Pz+sWLECJSUlGjPbPKk358Df3x9KpRIODg6IiIhAfX09SktLAQBNTU1IS0tDaGgowsLCYGtri40bN0IikRjsWHfFy8sLAFBQUGDUfgYbTmiM9YPCwkLU1dVh4sSJGssnTZoEqVSqcUvQ0CZOnAi5XG6U0kPGVFFRASKCXC7XqX18fDxGjx6N1NRUnD9/Xmt9X8/B02WK+rvM05M6jslPP/1k1H4GG05ojPWDjmHW1tbWWuts/3979/OSShfGAfwrOTRGREokYRSWQYsWQZuKWkTgpoW5CF1GGwlKonBRiwglWxT9B+GiWr0ltqmtqyKIilqFBAURgf02+qHp8y7um/f1du+bc+9MY/M+n+VRz3k8Z5gHxzPzlJcjkUgoOn5xcTHi8biiY8jt+fkZAD7cJPFGFEWEQiHodDoMDAzg6ekp53W510DNUkQGgwHA9zli33BCY+wTlJeXA8BPT5q3t7eorq5WbOxUKqX4GEp4O2lLuZG4ra0No6OjiMViCAQCOa/JvQb/LndEP9wHurW1JakvqZLJJIDvc8S+4YTG2CdoampCaWkpdnZ2ctq3t7eRTCbR0tKSbdPr9dnLWnKIRqMgIrS2tio2hhIqKyuh0+kk318WCATQ2NiIvb29nHYpa5APNUsRvc2J2Wz+9LELGSc0xj6BKIoYGxtDOBzG0tIS7u/vcXh4iMHBQVRVVcHj8WTfa7PZcH19jUgkglQqhXg8jtPT03d9mkwmnJ+f4+TkBIlEIpugMpkMbm5u8Pr6ioODA4yMjKCmpgb9/f2yjCG1hNDvKikpQV1dXbaafL7eLj0WFRW9a893DfId56NSRG63G2azWfZHb73NiRK1Cr80NbdYKom37TMl/c7xlclkaHZ2lhoaGkgQBDIajeR0Ouno6CjnfVdXV9TV1UWiKJLVaqXh4WHy+XwEgGw2W3b7/e7uLtXW1pLBYKCOjg66uLggj8dDgiCQxWIhvV5PZWVl1NvbS8fHx7KNkU8JoV+BxG3jXq+XBEGgx8fHbFs4HKb6+noCQBUVFTQ0NPTTz/p8vnfb9vNZg3zLFBF9XIrI6XQSAJqcnPzP7ymlzBMRUU9PD1ksFspkMvlN5D+kzv9Xo9kzPic0pqRCPb48Hg+ZTCa1w/glqSfUWCxGer2eFhcXFYxKOel0mjo7O2lhYUG2Pi8vL0kURZqbm5P8Wa0nNL7kyJjGaOlp7DabDX6/H36/Hw8PD2qHI0k6nUYkEkEikZC1+sXU1BSam5vh9Xpl61MrOKExxgra+Pg4+vr64Ha7v9QDiKPRKFZXV7GxsZH3vXQfmZ+fx/7+PtbX1yEIgix9agknNMY0YmJiAqFQCHd3d7BarVhZWVE7JNlMT0/D6/ViZmZG7VDy1t3djeXl5ZxnZv6JtbU1vLy8IBqNwmg0ytKn1ujVDoAxJo9gMIhgMKh2GIqx2+2w2+1qh6Eah8MBh8OhdhgFjX+hMcYY0wROaIwxxjSBExpjjDFN4ITGGGNMEzihMcYY0wTN73LU6XRqh8A0jI8v6VwuF1wul9phMA3SERGpHYQSzs7OsLm5qXYYjDFWUNrb279cKaF8aTahMcYY+3/h/9AYY4xpAic0xhhjmsAJjTHGmCboAfyldhCMMcbYn/obxfgIo88eO3YAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.utils.vis_utils import plot_model\n",
    "model = Sequential()\n",
    "model.add(Dense(2, input_dim=1, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "plot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "colab": {
   "name": "Homework 2 - 4.11.2021 - Neural network-Manual-sklearn-keras.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
